{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d152321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce87b9d3",
   "metadata": {},
   "source": [
    "### PRODUCTS EXPIRATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13754b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# products and their expiration dates\n",
    "expiration = {\n",
    "    2: [\n",
    "        '01. Сэндвич \"Классический\"', \n",
    "        '02. Сэндвич \"С курицей\"',\n",
    "        '03. Сэндвич Сырный Соус',\n",
    "        '04. Сэндвич \"PICNIC\"',\n",
    "        '06. Хот - Дог',\n",
    "        '08. Гамбургер с котлетой',\n",
    "        '29. Burrito стрипсы'\n",
    "        ],\n",
    "\n",
    "    3: [\n",
    "        '16. Багет пшенично-ржаной',\n",
    "        '15. Багет пшеничный',\n",
    "        '21. Тостовый хлеб',\n",
    "        '23. Батон нарезной',\n",
    "        '43. Батон к чаю',\n",
    "        '44. Батон отрубной',\n",
    "        \"45. Батон ''Царский''\"\n",
    "        ],\n",
    "\n",
    "    5: [\n",
    "        '10. Булочка Ярославка',\n",
    "        '59. Булочки для фуда БУРГЕР',\n",
    "        '60. Булочки для фуда Хот-Дог',\n",
    "        '18. Лаваш',\n",
    "        '17. Ролл',\n",
    "        \"42. Батон ''Живая Рожь''\"\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06969ca4",
   "metadata": {},
   "source": [
    "### ADD NEW DATA TO MAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_data_to_initial_dataset():\n",
    "    # reading data\n",
    "    initial_DF = pd.read_csv('dataset/initial_dataset.csv')\n",
    "    print(initial_DF.shape)\n",
    "    temp_df = pd.read_excel('temp/data.xlsx', skipfooter=3)\n",
    "    \n",
    "    # renaming columns\n",
    "    temp_df.rename({\n",
    "        'Дата.1': 'Date',\n",
    "        'Маршрут': 'District',\n",
    "        'Контрагент': 'Address',\n",
    "        'Номенклатура': 'Product',\n",
    "        'Количество': 'Sales',\n",
    "        'Обмен': 'Returns'\n",
    "    }, axis=1, inplace=True)\n",
    "    \n",
    "    # concating new and old data\n",
    "    df = pd.concat([initial_DF, temp_df])\n",
    "    \n",
    "    # converting a date columns to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # sorting data by date\n",
    "    df = df.sort_values('Date').reset_index(drop=True).drop_duplicates()\n",
    "    \n",
    "    # deleting unnecessary data according to date limit\n",
    "    date_limit = df['Date'].iloc[-1] - timedelta(weeks=5)\n",
    "    df = df[df['Date'] >= date_limit]\n",
    "    \n",
    "    print(df.shape)\n",
    "    df.to_csv('dataset/initial_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87c37f",
   "metadata": {},
   "source": [
    "### SHIFTING RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8fa866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifting_returns_and_merging_with_sales(initial_DF, days_to_shift):\n",
    "    if days_to_shift not in [2, 3, 5]:\n",
    "        return\n",
    "    \n",
    "    # reading data\n",
    "    initial_DF['Date'] = pd.to_datetime(initial_DF['Date'])\n",
    "    \n",
    "    # filtering data by products\n",
    "    df = initial_DF[initial_DF['Product'].isin(expiration[days_to_shift])]\n",
    "    \n",
    "    # seperating sales and returns\n",
    "    df_sales = df.drop(['Returns'], axis=1)\n",
    "    df_returns = df.drop(['Sales'], axis=1)\n",
    "    \n",
    "    # shifting date \n",
    "    df_returns['Date'] = df_returns['Date'] - timedelta(days=days_to_shift)\n",
    "    \n",
    "    # getting date range of a final df\n",
    "    date_range = df_sales.merge(\n",
    "        df_returns,\n",
    "        on=['Date', 'District', 'Address', 'Product'],\n",
    "        how='inner'\n",
    "    )['Date'].unique()\n",
    "    \n",
    "    # merging sales and returns\n",
    "    main_DF = df_sales.merge(\n",
    "        df_returns,\n",
    "        on=['Date', 'District', 'Address', 'Product'],\n",
    "        how='outer'\n",
    "    )\n",
    "    \n",
    "    # final data\n",
    "    main_DF = main_DF[main_DF['Date'].isin(date_range)].fillna(0)\n",
    "\n",
    "    return main_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a854872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting 3 seperate DFs of 3 groups of products with shifted returns\n",
    "initial_DF = pd.read_csv('dataset/initial_dataset.csv')\n",
    "\n",
    "two_days_expiricy_DF = shifting_returns_and_merging_with_sales(initial_DF, days_to_shift=2)\n",
    "three_days_expiricy_DF = shifting_returns_and_merging_with_sales(initial_DF, days_to_shift=3)\n",
    "five_days_expiricy_DF = shifting_returns_and_merging_with_sales(initial_DF, days_to_shift=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd110122",
   "metadata": {},
   "source": [
    "### FILL MISSED ADDRESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ea671",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_DF = pd.concat([two_days_expiricy_DF, three_days_expiricy_DF, five_days_expiricy_DF])\n",
    "combined_DF.sort_values('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_date_to_get_data_about_stores = combined_DF['Date'].iloc[-1] - timedelta(weeks=2)\n",
    "condition = (combined_DF['Date'] >= limit_date_to_get_data_about_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_addresses = combined_DF[condition]['Address'].unique()\n",
    "all_products = combined_DF[condition]['Product'].unique()\n",
    "\n",
    "len(all_addresses), len(all_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15291b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = combined_DF.iloc[0]['Date']\n",
    "end_date = combined_DF.iloc[-1]['Date'] + timedelta(weeks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd90480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Наполняем список комбиниациями\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    combinations = list(product(all_products, all_addresses))\n",
    "    data.extend([(current_date, address, product) for product, address in combinations])\n",
    "    current_date += timedelta(days=1)\n",
    "    \n",
    "full_DF = pd.DataFrame(data, columns=[\"Date\", \"Address\", \"Product\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем колонну продаж и возвратов\n",
    "full_DF['Sales'] = 0\n",
    "full_DF['Returns'] = 0\n",
    "\n",
    "# Далем слияние двух таблиц, чтобы продажи и возвраты встали на место.\n",
    "main_DF = full_DF[['Date', 'Address', 'Product']].merge(\n",
    "    combined_DF[['Date', 'Address', 'Product', 'Sales', 'Returns']], \n",
    "    on=['Date', 'Address', 'Product'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Заполняем 'null' нулями\n",
    "main_DF = main_DF.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132af44",
   "metadata": {},
   "source": [
    "### DELETING ADDRESS-PRODUCT COMBINATIONS THAT ARE NOT RELEVANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_date_to_get_data_about_store_sales = main_DF.sort_values('Date')['Date'].iloc[-1] - timedelta(weeks=2)\n",
    "condition = (main_DF['Date'] >= limit_date_to_get_data_about_store_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46920191",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_add_prod_sales_DF = main_DF[condition].groupby(['Address', 'Product']).agg({\n",
    "    'Sales': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8c1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_address_product_combinations_DF = grouped_add_prod_sales_DF[grouped_add_prod_sales_DF['Sales'] > 0].drop('Sales', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_address_product_combinations_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516dbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF = main_DF.merge(existing_address_product_combinations_DF,\n",
    "             on=['Address', 'Product'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392721dd",
   "metadata": {},
   "source": [
    "### REMOVE SUNDAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF['Weekday'] = main_DF['Date'].dt.weekday\n",
    "main_DF = main_DF[main_DF['Weekday'] != 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfcfd52",
   "metadata": {},
   "source": [
    "### SHIFTING SALES AND RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF.sort_values(by=['Address', 'Product', 'Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee83e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_shift = [1, 2, 3, 4, 5, 6, 13, 20]\n",
    "for day in days_to_shift:\n",
    "    main_DF[f'Sales_{day + 1}'] = main_DF.groupby(['Address', 'Product'])['Sales'].shift(day)\n",
    "    main_DF[f'Returns_{day + 1}'] = main_DF.groupby(['Address', 'Product'])['Returns'].shift(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f112f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219591ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF.groupby(['Date'])['Sales', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6', 'Sales_14', 'Sales_21'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf64a6",
   "metadata": {},
   "source": [
    "### STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f4205",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "main_DF['Returns_percentage'] = main_DF['Returns_7'] / (main_DF['Sales_7'] + main_DF['Returns_7'])\n",
    "\n",
    "main_DF['Mean_sales_in_week'] = main_DF[['Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6', 'Sales_7']].mean(axis=1)\n",
    "main_DF['Median_sales_in_week'] = main_DF[['Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6', 'Sales_7']].median(axis=1)\n",
    "\n",
    "main_DF['Mean_sales_in_3_weeks'] = main_DF[['Sales_7', 'Sales_14', 'Sales_21']].mean(axis=1)\n",
    "main_DF['Median_sales_in_3_weeks'] = main_DF[['Sales_7', 'Sales_14', 'Sales_21']].median(axis=1)\n",
    "\n",
    "main_DF['No_sales_in_week'] = main_DF[['Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6', 'Sales_7']].sum(axis=1) == 0\n",
    "main_DF['No_returns_in_week'] = main_DF[['Returns_2', 'Returns_3', 'Returns_4', 'Returns_5', 'Returns_6', 'Returns_7',]].sum(axis=1) == 0\n",
    "\n",
    "main_DF['Total_sales_in_week'] = main_DF[['Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6', 'Sales_7']].sum(axis=1)\n",
    "\n",
    "main_DF['Mean_returns_in_week'] = main_DF[['Returns_2', 'Returns_3', 'Returns_4', 'Returns_5', 'Returns_6', 'Returns_7',]].mean(axis=1)\n",
    "main_DF['Mean_returns_in_3_weeks'] = main_DF[['Returns_7', 'Sales_14', 'Returns_21']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd294046",
   "metadata": {},
   "source": [
    "### SET BACK DISTRICTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d78eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_address_DF = combined_DF.sort_values('Date')[['District', 'Address']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aabe3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_address_DF = district_address_DF.drop_duplicates('Address', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93413d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_address_DF['Address'].unique().shape, district_address_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464042e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF = main_DF.merge(district_address_DF, on='Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = list(main_DF.columns)\n",
    "columns_order.insert(1, columns_order.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF = main_DF[columns_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac91936",
   "metadata": {},
   "source": [
    "### HANDLE SPECIAL ORDERS AND ANOMALIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd776594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isAnomaly(data):\n",
    "    # Calculate mean and standard deviation\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "\n",
    "    # Calculate quartiles and IQR\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Calculate bounds for outliers using IQR\n",
    "    const = 2\n",
    "    lower_bound = Q1 - const * IQR\n",
    "    upper_bound = Q3 + const * IQR\n",
    "\n",
    "    iqr_anomalies = [x for x in data if x < lower_bound or x > upper_bound]\n",
    "    \n",
    "    return data['Sales_7'] in iqr_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b26f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "main_DF['isAnomaly'] = False\n",
    "\n",
    "condition = main_DF['Sales_7'] > 10\n",
    "columns_to_check = ['Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6', 'Sales_7']\n",
    "\n",
    "\n",
    "main_DF.loc[condition,'isAnomaly'] = main_DF[condition][columns_to_check].apply(isAnomaly, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF['Address'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d926e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF[main_DF['isAnomaly'] == True]['Address'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66994b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF['isAnomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb199c",
   "metadata": {},
   "source": [
    "### PREDICT DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_date_to_predict = main_DF.sort_values('Date')['Date'].iloc[-1] - timedelta(days=5)\n",
    "condition = (main_DF['Date'] == limit_date_to_predict)\n",
    "\n",
    "predict_DF = main_DF[condition].drop(['Sales', 'Returns'], axis=1)\n",
    "predict_DF['Predict'] = predict_DF['Sales_7']\n",
    "predict_DF['Delivered_7'] = predict_DF['Sales_7'] + predict_DF['Returns_7']\n",
    "\n",
    "predict_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b6045",
   "metadata": {},
   "source": [
    "### TREND AND WEATHER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trend(data):\n",
    "    y1, y2, y3 = data[0], data[1], data[2]\n",
    "    trend = ((y3 - y2) + (y2 - y1)) / 2\n",
    "    \n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_weather_forecast():\n",
    "    HEADERS = {\n",
    "        \"user-agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Mobile Safari/537.36\",\n",
    "        \"accept\": \"*/*\"\n",
    "    }\n",
    "\n",
    "    URL = \"https://www.gismeteo.kz/weather-astana-5164/10-days/\"\n",
    "    r = requests.get(URL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    date_range = pd.date_range(start=datetime.now().date(), end=(datetime.now() + timedelta(days=9)).date())\n",
    "\n",
    "    temperature_container = soup.find(\"div\", class_=\"widget-row-chart widget-row-chart-temperature-air row-with-caption\")\n",
    "    temperature_elements = temperature_container.find_all(\"temperature-value\") # type: ignore\n",
    "    temperature_values = [temp['value'] for temp in temperature_elements if 'value' in temp.attrs]\n",
    "    temperature_values = [int(temp) for temp in temperature_values][0::2]\n",
    "\n",
    "    wind_speed_container = soup.find(\"div\", class_=\"widget-row widget-row-wind row-wind-gust row-with-caption\")\n",
    "    wind_speed_elements = wind_speed_container.find_all(\"speed-value\") # type: ignore\n",
    "    wind_speed_values = [temp['value'] for temp in wind_speed_elements if 'value' in temp.attrs]\n",
    "    wind_speed_values = [int(temp) for temp in wind_speed_values]\n",
    "\n",
    "    humidity_container = soup.find(\"div\", class_=\"widget-row widget-row-precipitation-bars row-with-caption\")\n",
    "    humidity_elements = humidity_container.find_all(\"div\", class_= \"row-item\")\n",
    "\n",
    "    humidity_values_uncleaned = [item.text for item in humidity_elements]\n",
    "\n",
    "    humidity_values = []\n",
    "    for temp in humidity_values_uncleaned:\n",
    "        value_str = temp.strip().replace(',', '.')\n",
    "\n",
    "        if value_str:\n",
    "            humidity_values.append(float(value_str))\n",
    "\n",
    "    weather_DF = pd.DataFrame({\n",
    "        'Date': date_range,\n",
    "        'Temperature': temperature_values,\n",
    "        'Wind_speed': wind_speed_values,\n",
    "        'Humidity': humidity_values\n",
    "    })\n",
    "    \n",
    "    return weather_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_weather_past():\n",
    "    weather_past_DF = pd.read_excel(f\"temp/weather/{os.listdir('temp/weather')[0]}\", skiprows=6)\n",
    "    weather_past_DF = weather_past_DF[['Местное время в Астане', 'T', 'Ff', 'U']]\n",
    "\n",
    "    weather_past_DF.rename({\n",
    "        'Местное время в Астане': 'Date',\n",
    "        'T': 'Temperature',\n",
    "        'Ff': 'wind_speed_values',\n",
    "        'U': 'humidity_values'\n",
    "    }, axis=1, inplace=True)\n",
    "\n",
    "    weather_past_DF['Date'] = pd.to_datetime(weather_past_DF['Date'], dayfirst=True)\n",
    "    weather_past_DF['Time'] = (weather_past_DF['Date'].dt.time).astype(str)\n",
    "    \n",
    "    time_to_filter = ['08:00:00', '11:00:00', '14:00:00', '17:00:00', '20:00:00']\n",
    "    weather_past_DF = weather_past_DF[weather_past_DF['Time'].isin(time_to_filter)]\n",
    "    weather_past_DF['Date'] = weather_past_DF['Date'].dt.date\n",
    "    weather_past_DF = weather_past_DF.drop('Time', axis=1)\n",
    "\n",
    "    weather_past_DF = weather_past_DF.groupby('Date').mean().reset_index()\n",
    "    \n",
    "    return weather_past_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_DF['Trend'] = predict_DF[['Sales_21', 'Sales_14', 'Sales_7']].apply(calculate_trend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471edab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_past_DF = parse_weather_past()\n",
    "weather_past_DF['Date'] = pd.to_datetime(weather_past_DF['Date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_DF = parse_weather_forecast()\n",
    "# predict_DF = predict_DF.merge(weather_DF, on='Date', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e746f2",
   "metadata": {},
   "source": [
    "### MATH MODEL FORMULA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_DF.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_sales(value):\n",
    "    if value == 0:\n",
    "        return 'A'\n",
    "    elif 0 < value <= 10:\n",
    "        return 'B'\n",
    "    elif 11 < value <= 20:\n",
    "        return 'C'\n",
    "    elif 21 < value <= 30:\n",
    "        return 'D'\n",
    "    elif 31 < value:\n",
    "        return 'E'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "predict_DF['Sales_7_category'] = predict_DF['Sales_7'].apply(categorize_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_predict(data):\n",
    "    if data['Sales_7_category'] == 'A':\n",
    "        return 1\n",
    "    \n",
    "    elif data['Sales_7_category'] == 'B':\n",
    "        return data['Predict'] + 1\n",
    "    \n",
    "    elif data['Sales_7_category'] == 'C':\n",
    "        return data['Predict'] + 2\n",
    "    \n",
    "    elif data['Sales_7_category'] == 'D':\n",
    "        return data['Predict'] * 1.1\n",
    "    \n",
    "    elif data['Sales_7_category'] == 'E':\n",
    "        return data['Predict'] * 1.08\n",
    "    \n",
    "    \n",
    "def decrease_predict(data):\n",
    "    if data['Sales_7_category'] == 'A':\n",
    "        return 1\n",
    "\n",
    "    elif data['Sales_7_category'] == 'B':\n",
    "        return data['Predict'] - 1\n",
    "    \n",
    "    elif data['Sales_7_category'] == 'C':\n",
    "        return data['Predict'] - 2\n",
    "    \n",
    "    elif data['Sales_7_category'] == 'D':\n",
    "        return data['Predict'] / 1.1\n",
    "    \n",
    "    elif data['Sales_7_category'] == 'E':\n",
    "        return data['Predict'] / 1.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c93ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREND UP, RETURNS UP, PREDICT UP\n",
    "condition = (predict_DF['Trend'] > 0) & (predict_DF['Returns_percentage'] > 0.1)\n",
    "predict_DF.loc[condition, 'Predict'] = predict_DF[condition][['Predict', 'Sales_7_category']].apply(increase_predict, axis=1)\n",
    "\n",
    "print(predict_DF[condition].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780cb4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREND DOWN, RETURNS DOWN, PREDICT UP\n",
    "condition = (predict_DF['Trend'] < 0) & (predict_DF['Returns_percentage'] < 0.08)\n",
    "predict_DF.loc[condition, 'Predict'] = predict_DF[condition][['Predict', 'Sales_7_category']].apply(increase_predict, axis=1)\n",
    "\n",
    "print(predict_DF[condition].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e5120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREND UP, RETURNS DOWN, PREDICT UP\n",
    "condition = (predict_DF['Trend'] > 0) & (predict_DF['Returns_percentage'] < 0.08)\n",
    "predict_DF.loc[condition, 'Predict'] = predict_DF[condition][['Predict', 'Sales_7_category']].apply(increase_predict, axis=1)\n",
    "\n",
    "print(predict_DF[condition].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREND DOWN, RETURNS UP, PREDICT UP\n",
    "condition = (predict_DF['Trend'] < 0) & (predict_DF['Returns_percentage'] > 0.1)\n",
    "predict_DF.loc[condition, 'Predict'] = predict_DF[condition][['Predict', 'Sales_7_category']].apply(decrease_predict, axis=1)\n",
    "\n",
    "print(predict_DF[condition].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO TREND, RETURNS 8-10%, REMAINS THE SAME\n",
    "condition = (predict_DF['Trend'] == 0) & (predict_DF['Returns_percentage'] >= 0.08) & (predict_DF['Returns_percentage'] <= 0.1)\n",
    "predict_DF.loc[condition, 'Predict'] = predict_DF.loc[condition, 'Delivered_7']\n",
    "\n",
    "predict_DF.loc[condition].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4888ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO TREND, RETURNS DOWN, PREDICT UP\n",
    "condition = (predict_DF['Trend'] == 0) & (predict_DF['Returns_percentage'] < 0.08)\n",
    "predict_DF.loc[condition, 'Predict'] = predict_DF[condition][['Predict', 'Sales_7_category']].apply(increase_predict, axis=1)\n",
    "\n",
    "predict_DF.loc[condition].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfaddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO TREND, RETURNS UP, PREDICT DOWN\n",
    "condition = (predict_DF['Trend'] == 0) & (predict_DF['Returns_percentage'] > 0.1)\n",
    "predict_DF.loc[condition, 'Predict'] = predict_DF[condition][['Predict', 'Sales_7_category']].apply(decrease_predict, axis=1)\n",
    "\n",
    "predict_DF.loc[condition].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREND UP, RETURNS 8-10%, PREDICT UP\n",
    "condition = (predict_DF['Trend'] > 0) & (predict_DF['Returns_percentage'] >= 0.08) & (predict_DF['Returns_percentage'] <= 0.1)\n",
    "predict_DF.loc[condition, 'Predict'] = predict_DF[condition][['Predict', 'Sales_7_category']].apply(increase_predict, axis=1)\n",
    "\n",
    "predict_DF.loc[condition].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d6d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREND DOWN, RETURNS 8-10%, PREDICT DOWN\n",
    "condition = (predict_DF['Trend'] < 0) & (predict_DF['Returns_percentage'] >= 0.08) & (predict_DF['Returns_percentage'] <= 0.1)\n",
    "predict_DF.loc[condition, 'Predict'] = predict_DF[condition][['Predict', 'Sales_7_category']].apply(decrease_predict, axis=1)\n",
    "\n",
    "predict_DF.loc[condition].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_DF[predict_DF['District'] == '46 маршрут'].to_excel('prediction/46.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc77c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_DF['Weekday'] = initial_DF['Date'].dt.weekday + 1\n",
    "initial_DF[initial_DF['District'] == '01 маршрут'].to_excel('1маршрут.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
