{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d152321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce87b9d3",
   "metadata": {},
   "source": [
    "### PRODUCTS EXPIRATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13754b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# products and their expiration dates\n",
    "expiration = {\n",
    "    2: [\n",
    "        '01. Сэндвич \"Классический\"', \n",
    "        '02. Сэндвич \"С курицей\"',\n",
    "        '03. Сэндвич Сырный Соус',\n",
    "        '04. Сэндвич \"PICNIC\"',\n",
    "        '06. Хот - Дог',\n",
    "        '08. Гамбургер с котлетой',\n",
    "        '29. Burrito стрипсы'\n",
    "        ],\n",
    "\n",
    "    3: [\n",
    "        '16. Багет пшенично-ржаной',\n",
    "        '15. Багет пшеничный',\n",
    "        '21. Тостовый хлеб',\n",
    "        '23. Батон нарезной',\n",
    "        '43. Батон к чаю',\n",
    "        '44. Батон отрубной',\n",
    "        \"45. Батон ''Царский''\"\n",
    "        ],\n",
    "\n",
    "    5: [\n",
    "        '10. Булочка Ярославка',\n",
    "        '59. Булочки для фуда БУРГЕР',\n",
    "        '60. Булочки для фуда Хот-Дог',\n",
    "        '18. Лаваш',\n",
    "        '17. Ролл',\n",
    "        \"42. Батон ''Живая Рожь''\"\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06969ca4",
   "metadata": {},
   "source": [
    "### ADD NEW DATA TO MAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e918708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_data_to_initial_dataset():\n",
    "    # reading data\n",
    "    initial_DF = pd.read_csv('dataset/initial_dataset.csv')\n",
    "    print(initial_DF.shape)\n",
    "    temp_df = pd.read_excel('temp/data.xlsx', skipfooter=3)\n",
    "    \n",
    "    # renaming columns\n",
    "    temp_df.rename({\n",
    "        'Дата.1': 'Date',\n",
    "        'Маршрут': 'District',\n",
    "        'Контрагент': 'Address',\n",
    "        'Номенклатура': 'Product',\n",
    "        'Количество': 'Sales',\n",
    "        'Обмен': 'Returns'\n",
    "    }, axis=1, inplace=True)\n",
    "    \n",
    "    # concating new and old data\n",
    "    df = pd.concat([initial_DF, temp_df])\n",
    "    \n",
    "    # converting a date columns to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # sorting data by date\n",
    "    df = df.sort_values('Date').reset_index(drop=True).drop_duplicates()\n",
    "    \n",
    "    # deleting unnecessary data according to date limit\n",
    "    date_limit = df['Date'].iloc[-1] - timedelta(weeks=5)\n",
    "    df = df[df['Date'] >= date_limit]\n",
    "    \n",
    "    print(df.shape)\n",
    "    df.to_csv('dataset/initial_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87c37f",
   "metadata": {},
   "source": [
    "### SHIFTING RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b8fa866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifting_returns_and_merging_with_sales(days_to_shift):\n",
    "    if days_to_shift not in [2, 3, 5]:\n",
    "        return\n",
    "    \n",
    "    # reading data\n",
    "    initial_DF = pd.read_csv('dataset/initial_dataset.csv')\n",
    "    initial_DF['Date'] = pd.to_datetime(initial_DF['Date'])\n",
    "    \n",
    "    # filtering data by products\n",
    "    df = initial_DF[initial_DF['Product'].isin(expiration[days_to_shift])]\n",
    "    \n",
    "    # seperating sales and returns\n",
    "    df_sales = df.drop(['Returns'], axis=1)\n",
    "    df_returns = df.drop(['Sales'], axis=1)\n",
    "    \n",
    "    # shifting date \n",
    "    df_returns['Date'] = df_returns['Date'] - timedelta(days=days_to_shift)\n",
    "    \n",
    "    # getting date range of a final df\n",
    "    date_range = df_sales.merge(\n",
    "        df_returns,\n",
    "        on=['Date', 'District', 'Address', 'Product'],\n",
    "        how='inner'\n",
    "    )['Date'].unique()\n",
    "    \n",
    "    # merging sales and returns\n",
    "    main_DF = df_sales.merge(\n",
    "        df_returns,\n",
    "        on=['Date', 'District', 'Address', 'Product'],\n",
    "        how='outer'\n",
    "    )\n",
    "    \n",
    "    # final data\n",
    "    main_DF = main_DF[main_DF['Date'].isin(date_range)].fillna(0)\n",
    "\n",
    "    return main_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a854872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting 3 seperate DFs of 3 groups of products with shifted returns\n",
    "two_days_expiricy_DF = shifting_returns_and_merging_with_sales(days_to_shift=2)\n",
    "three_days_expiricy_DF = shifting_returns_and_merging_with_sales(days_to_shift=3)\n",
    "five_days_expiricy_DF = shifting_returns_and_merging_with_sales(days_to_shift=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd110122",
   "metadata": {},
   "source": [
    "### FILL MISSED ADDRESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc1ea671",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_DF = pd.concat([two_days_expiricy_DF, three_days_expiricy_DF, five_days_expiricy_DF])\n",
    "combined_DF.sort_values('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "331a6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_date_to_get_data_about_stores = combined_DF['Date'].iloc[-1] - timedelta(weeks=2)\n",
    "condition = (combined_DF['Date'] >= limit_date_to_get_data_about_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff4d3256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2396, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_addresses = combined_DF[condition]['Address'].unique()\n",
    "all_products = combined_DF[condition]['Product'].unique()\n",
    "\n",
    "len(all_addresses), len(all_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15291b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = combined_DF.iloc[0]['Date']\n",
    "end_date = combined_DF.iloc[-1]['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd90480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Наполняем список комбиниациями\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    combinations = list(product(all_products, all_addresses))\n",
    "    data.extend([(current_date, address, product) for product, address in combinations])\n",
    "    current_date += timedelta(days=1)\n",
    "    \n",
    "full_DF = pd.DataFrame(data, columns=[\"Date\", \"Address\", \"Product\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13fd5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем колонну продаж и возвратов\n",
    "full_DF['Sales'] = 0\n",
    "full_DF['Returns'] = 0\n",
    "\n",
    "# Далем слияние двух таблиц, чтобы продажи и возвраты встали на место.\n",
    "main_DF = full_DF[['Date', 'Address', 'Product']].merge(\n",
    "    combined_DF[['Date', 'Address', 'Product', 'Sales', 'Returns']], \n",
    "    on=['Date', 'Address', 'Product'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Заполняем 'null' нулями\n",
    "main_DF = main_DF.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132af44",
   "metadata": {},
   "source": [
    "### DELETING ADDRESS-PRODUCT COMBINATIONS THAT ARE NOT RELEVANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed5d1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_date_to_get_data_about_store_sales = main_DF.sort_values('Date')['Date'].iloc[-1] - timedelta(weeks=2)\n",
    "condition = (main_DF['Date'] >= limit_date_to_get_data_about_store_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46920191",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_add_prod_sales_DF = main_DF[condition].groupby(['Address', 'Product']).agg({\n",
    "    'Sales': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce8c1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_address_product_combinations_DF = grouped_add_prod_sales_DF[grouped_add_prod_sales_DF['Sales'] > 0].drop('Sales', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b535e1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31075, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_address_product_combinations_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "516dbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF = main_DF.merge(existing_address_product_combinations_DF,\n",
    "             on=['Address', 'Product'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfcfd52",
   "metadata": {},
   "source": [
    "### SHIFTING SALES AND RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d7c3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF.sort_values(by=['Address', 'Product', 'Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fee83e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_shift = [1, 2, 3, 4, 5, 6, 7, 14, 21]\n",
    "for day in days_to_shift:\n",
    "    main_DF[f'Sales_{day}'] = main_DF.groupby(['Address', 'Product'])['Sales'].shift(day)\n",
    "    main_DF[f'Returns_{day}'] = main_DF.groupby(['Address', 'Product'])['Returns'].shift(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f112f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf64a6",
   "metadata": {},
   "source": [
    "### STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b0f4205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.38 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "main_DF['Returns_percentage'] = main_DF['Returns'] / (main_DF['Sales'] + main_DF['Returns'])\n",
    "\n",
    "main_DF['Mean_sales_in_week'] = main_DF[['Sales', 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6']].mean(axis=1)\n",
    "main_DF['Median_sales_in_week'] = main_DF[['Sales', 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6']].median(axis=1)\n",
    "\n",
    "main_DF['Mean_sales_in_3_weeks'] = main_DF[['Sales', 'Sales_14', 'Sales_21']].mean(axis=1)\n",
    "main_DF['Median_sales_in_3_weeks'] = main_DF[['Sales', 'Sales_14', 'Sales_21']].median(axis=1)\n",
    "\n",
    "main_DF['No_sales_in_week'] = main_DF[['Sales', 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6']].sum(axis=1) == 0\n",
    "main_DF['No_returns_in_week'] = main_DF[['Returns', 'Returns_1', 'Returns_2', 'Returns_3', 'Returns_4', 'Returns_5', 'Returns_6']].sum(axis=1) == 0\n",
    "\n",
    "main_DF['Total_sales_in_week'] = main_DF[['Sales', 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6']].sum(axis=1)\n",
    "\n",
    "main_DF['Mean_returns_in_week'] = main_DF[['Returns', 'Returns_1', 'Returns_2', 'Returns_3', 'Returns_4', 'Returns_5', 'Returns_6']].mean(axis=1)\n",
    "main_DF['Mean_returns_in_3_weeks'] = main_DF[['Returns', 'Sales_14', 'Returns_21']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd294046",
   "metadata": {},
   "source": [
    "### SET BACK DISTRICTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39d78eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_address_DF = combined_DF.sort_values('Date')[['District', 'Address']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aabe3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_address_DF = district_address_DF.drop_duplicates('Address', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a93413d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2469,), (2469, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "district_address_DF['Address'].unique().shape, district_address_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "464042e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF = main_DF.merge(district_address_DF, on='Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aff88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = list(main_DF.columns)\n",
    "columns_order.insert(1, columns_order.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d77b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF = main_DF[columns_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac91936",
   "metadata": {},
   "source": [
    "### HANDLE SPECIAL ORDERS AND ANOMALIES ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd776594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isAnomaly(data):\n",
    "    # Calculate mean and standard deviation\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "\n",
    "    # Calculate quartiles and IQR\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Calculate bounds for outliers using IQR\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    iqr_anomalies = [x for x in data if x < lower_bound or x > upper_bound]\n",
    "    \n",
    "    return data['Sales'] in iqr_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b26f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.36 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "main_DF['isAnomaly'] = False\n",
    "\n",
    "condition = main_DF['Sales'] > 10\n",
    "columns_to_check = ['Sales', 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5', 'Sales_6']\n",
    "\n",
    "\n",
    "main_DF.loc[condition,'isAnomaly'] = main_DF[condition][columns_to_check].apply(isAnomaly, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2341b880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2387,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_DF['Address'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d926e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1187,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_DF[main_DF['isAnomaly'] == True]['Address'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c33a33",
   "metadata": {},
   "source": [
    "### REMOVE SUNDAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ce7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_DF['Weekday'] = main_DF['Date'].dt.weekday\n",
    "main_DF = main_DF[main_DF['Weekday'] != 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222386af",
   "metadata": {},
   "source": [
    "### MATH MODEL FORMULA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
